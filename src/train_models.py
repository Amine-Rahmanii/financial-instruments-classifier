"""
Module d'entra√Ænement et d'√©valuation des mod√®les de classification
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    f1_score, precision_score, recall_score
)
import xgboost as xgb
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

class ModelTrainer:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.results = {}
        
        # Mapping des labels vers les noms
        self.label_names = {0: 'Stock', 1: 'ETF', 2: 'Bond'}
        
    def prepare_data(self, X, y, test_size=0.2, random_state=42):
        """Pr√©pare les donn√©es pour l'entra√Ænement"""
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # Normalisation
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        return X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test
        
    def train_logistic_regression(self, X_train, y_train):
        """Entra√Æne un mod√®le de r√©gression logistique"""
        print("üîÑ Entra√Ænement R√©gression Logistique...")
        
        # Grille de param√®tres
        param_grid = {
            'C': [0.1, 1, 10, 100],
            'max_iter': [1000, 2000],
            'solver': ['liblinear', 'lbfgs']
        }
        
        # GridSearch avec validation crois√©e
        lr = LogisticRegression(random_state=42)
        grid_search = GridSearchCV(
            lr, param_grid, cv=5, scoring='f1_macro', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        self.models['logistic_regression'] = grid_search.best_estimator_
        print(f"  ‚úÖ Meilleurs param√®tres: {grid_search.best_params_}")
        
        return grid_search.best_estimator_
    
    def train_random_forest(self, X_train, y_train):
        """Entra√Æne un mod√®le Random Forest"""
        print("üîÑ Entra√Ænement Random Forest...")
        
        # Grille de param√®tres
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, None],
            'min_samples_split': [5, 10],
            'min_samples_leaf': [2, 4]
        }
        
        # GridSearch avec validation crois√©e
        rf = RandomForestClassifier(random_state=42)
        grid_search = GridSearchCV(
            rf, param_grid, cv=5, scoring='f1_macro', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        self.models['random_forest'] = grid_search.best_estimator_
        print(f"  ‚úÖ Meilleurs param√®tres: {grid_search.best_params_}")
        
        return grid_search.best_estimator_
    
    def train_xgboost(self, X_train, y_train):
        """Entra√Æne un mod√®le XGBoost"""
        print("üîÑ Entra√Ænement XGBoost...")
        
        # Grille de param√®tres
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [6, 8, 10],
            'learning_rate': [0.01, 0.1, 0.2],
            'subsample': [0.8, 1.0]
        }
        
        # GridSearch avec validation crois√©e
        xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')
        grid_search = GridSearchCV(
            xgb_model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        self.models['xgboost'] = grid_search.best_estimator_
        print(f"  ‚úÖ Meilleurs param√®tres: {grid_search.best_params_}")
        
        return grid_search.best_estimator_
    
    def train_lightgbm(self, X_train, y_train):
        """Entra√Æne un mod√®le LightGBM"""
        print("üîÑ Entra√Ænement LightGBM...")
        
        # Grille de param√®tres
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [6, 8, 10],
            'learning_rate': [0.01, 0.1, 0.2],
            'num_leaves': [31, 50, 100]
        }
        
        # GridSearch avec validation crois√©e
        lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)
        grid_search = GridSearchCV(
            lgb_model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        self.models['lightgbm'] = grid_search.best_estimator_
        print(f"  ‚úÖ Meilleurs param√®tres: {grid_search.best_params_}")
        
        return grid_search.best_estimator_
    
    def evaluate_model(self, model, X_test, y_test, model_name):
        """√âvalue un mod√®le"""
        
        # Pr√©dictions
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
        
        # M√©triques
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='macro')
        precision = precision_score(y_test, y_pred, average='macro')
        recall = recall_score(y_test, y_pred, average='macro')
        
        # Rapport de classification
        class_report = classification_report(
            y_test, y_pred, 
            target_names=[self.label_names[i] for i in sorted(self.label_names.keys())],
            output_dict=True
        )
        
        # Matrice de confusion
        conf_matrix = confusion_matrix(y_test, y_pred)
        
        # Sauvegarder les r√©sultats
        self.results[model_name] = {
            'accuracy': accuracy,
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'classification_report': class_report,
            'confusion_matrix': conf_matrix,
            'predictions': y_pred,
            'probabilities': y_pred_proba
        }
        
        print(f"üìä {model_name}:")
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  F1-Score: {f1:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall: {recall:.4f}")
        
        return self.results[model_name]
    
    def get_feature_importance(self, model, feature_names, model_name, top_n=20):
        """R√©cup√®re l'importance des features"""
        
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
        elif hasattr(model, 'coef_'):
            importances = np.abs(model.coef_[0]) if len(model.coef_.shape) > 1 else np.abs(model.coef_)
        else:
            return None
        
        # Cr√©er un DataFrame avec les importances
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        return importance_df.head(top_n)
    
    def plot_confusion_matrices(self, save_path='models/confusion_matrices.png'):
        """G√©n√®re les matrices de confusion pour tous les mod√®les"""
        
        n_models = len(self.results)
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        class_names = [self.label_names[i] for i in sorted(self.label_names.keys())]
        
        for idx, (model_name, results) in enumerate(self.results.items()):
            if idx < len(axes):
                sns.heatmap(
                    results['confusion_matrix'], 
                    annot=True, 
                    fmt='d',
                    xticklabels=class_names,
                    yticklabels=class_names,
                    ax=axes[idx],
                    cmap='Blues'
                )
                axes[idx].set_title(f'{model_name.replace("_", " ").title()}')
                axes[idx].set_xlabel('Pr√©dictions')
                axes[idx].set_ylabel('Vraies valeurs')
        
        # Supprimer les axes vides
        for idx in range(len(self.results), len(axes)):
            fig.delaxes(axes[idx])
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"üìä Matrices de confusion sauvegard√©es: {save_path}")
    
    def plot_feature_importance(self, model, feature_names, model_name, save_path=None):
        """G√©n√®re un graphique d'importance des features"""
        
        importance_df = self.get_feature_importance(model, feature_names, model_name)
        
        if importance_df is not None:
            plt.figure(figsize=(10, 8))
            sns.barplot(data=importance_df.head(15), x='importance', y='feature')
            plt.title(f'Top 15 Features - {model_name.replace("_", " ").title()}')
            plt.xlabel('Importance')
            plt.tight_layout()
            
            if save_path is None:
                save_path = f'models/feature_importance_{model_name}.png'
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìä Importance des features sauvegard√©e: {save_path}")
            
            return importance_df
    
    def train_all_models(self, X, y, feature_names):
        """Entra√Æne tous les mod√®les"""
        
        print("üöÄ D√©but de l'entra√Ænement de tous les mod√®les...")
        
        # Pr√©parer les donn√©es
        X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test = self.prepare_data(X, y)
        
        # Entra√Æner les mod√®les
        self.train_logistic_regression(X_train_scaled, y_train)
        self.train_random_forest(X_train, y_train)  # Random Forest ne n√©cessite pas de normalisation
        self.train_xgboost(X_train, y_train)
        self.train_lightgbm(X_train, y_train)
        
        print("\nüìä √âvaluation des mod√®les...")
        
        # √âvaluer les mod√®les
        self.evaluate_model(self.models['logistic_regression'], X_test_scaled, y_test, 'logistic_regression')
        self.evaluate_model(self.models['random_forest'], X_test, y_test, 'random_forest')
        self.evaluate_model(self.models['xgboost'], X_test, y_test, 'xgboost')
        self.evaluate_model(self.models['lightgbm'], X_test, y_test, 'lightgbm')
        
        # G√©n√©rer les visualisations
        self.plot_confusion_matrices()
        
        # Feature importance pour les mod√®les tree-based
        for model_name in ['random_forest', 'xgboost', 'lightgbm']:
            self.plot_feature_importance(self.models[model_name], feature_names, model_name)
        
        # Sauvegarder les mod√®les
        self.save_models()
        
        # Afficher le r√©sum√©
        self.print_summary()
        
        return self.models, self.results
    
    def save_models(self):
        """Sauvegarde tous les mod√®les"""
        
        for model_name, model in self.models.items():
            model_path = f'models/{model_name}.pkl'
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
        
        # Sauvegarder le scaler
        with open('models/scaler.pkl', 'wb') as f:
            pickle.dump(self.scaler, f)
        
        # Sauvegarder les r√©sultats
        with open('models/results.pkl', 'wb') as f:
            pickle.dump(self.results, f)
        
        print("üíæ Mod√®les sauvegard√©s dans le dossier 'models/'")
    
    def print_summary(self):
        """Affiche un r√©sum√© des performances"""
        
        print("\n" + "="*60)
        print("üìä R√âSUM√â DES PERFORMANCES")
        print("="*60)
        
        # Cr√©er un DataFrame de r√©sum√©
        summary_data = []
        for model_name, results in self.results.items():
            summary_data.append({
                'Mod√®le': model_name.replace('_', ' ').title(),
                'Accuracy': f"{results['accuracy']:.4f}",
                'F1-Score': f"{results['f1_score']:.4f}",
                'Precision': f"{results['precision']:.4f}",
                'Recall': f"{results['recall']:.4f}"
            })
        
        summary_df = pd.DataFrame(summary_data)
        print(summary_df.to_string(index=False))
        
        # Meilleur mod√®le
        best_model = max(self.results.keys(), key=lambda x: self.results[x]['f1_score'])
        print(f"\nüèÜ Meilleur mod√®le: {best_model.replace('_', ' ').title()}")
        print(f"   F1-Score: {self.results[best_model]['f1_score']:.4f}")

def main():
    """Fonction principale pour entra√Æner les mod√®les"""
    
    print("üìÇ Chargement des donn√©es...")
    
    # Charger les donn√©es
    X = pd.read_csv('data/X_features.csv')
    y = pd.read_csv('data/y_labels.csv').values.ravel()
    feature_names = pd.read_csv('data/feature_names.csv')['feature'].tolist()
    
    print(f"‚úÖ Donn√©es charg√©es: {X.shape[0]} observations, {X.shape[1]} features")
    
    # Entra√Æner les mod√®les
    trainer = ModelTrainer()
    models, results = trainer.train_all_models(X, y, feature_names)
    
    print("\n‚úÖ Entra√Ænement termin√©!")

if __name__ == "__main__":
    main()
